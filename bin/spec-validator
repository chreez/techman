#!/usr/bin/env bash

set -euo pipefail

# Default values
JSON_OUTPUT=false
DIFF_MODE=false
DIFF_FILE=""
ROOT_SPEC_FILE=""
SPEC_FILE=""
DEBUG=${DEBUG:-0}
TEST_LLM=false
DRY_RUN=false

# Model preference based on spec v0.5.2
MODEL_PREFERENCE=("claude-3-5-sonnet-20241022" "gpt-4o-2024-08-06" "gpt-4-turbo-2024-04-09")

usage() {
    cat << 'EOF'
Usage: spec-validator [OPTIONS] <spec_file>
       spec-validator [OPTIONS] --diff <diff_file> <root_spec_file>

Validates a spec file against the core spec-validator logic using Claude or OpenAI APIs.

OPTIONS:
    --json          Output results in JSON format
    --diff <file>   Validate only the diff content (use '-' for stdin)
                    When using --diff, a root spec file is REQUIRED for context
    --test-llm      Test LLM integration
    --dry-run       Show prompt without calling LLM
    -h, --help      Show this help message

REQUIRED:
    Either ANTHROPIC_API_KEY or OPENAI_API_KEY environment variable must be set.

EXAMPLES:
    spec-validator specs/example.md
    spec-validator --json specs/example.md > result.json
    git diff --cached specs/ | spec-validator --diff - specs/target-spec.md
    spec-validator --diff changes.patch specs/my-feature.md
EOF
    exit 1
}

error() {
    echo "Error: $1" >&2
    exit 1
}

debug() {
    if [[ "$DEBUG" == "1" ]]; then
        echo "[DEBUG] $1" >&2
    fi
}

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        --json)
            JSON_OUTPUT=true
            shift
            ;;
        --diff)
            DIFF_MODE=true
            DIFF_FILE="$2"
            shift 2
            ;;
        --test-llm)
            TEST_LLM=true
            shift
            ;;
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        -h|--help)
            usage
            ;;
        -*)
            error "Unknown option: $1"
            ;;
        *)
            if [[ "$DIFF_MODE" == true ]] && [[ -z "$ROOT_SPEC_FILE" ]]; then
                ROOT_SPEC_FILE="$1"
            else
                SPEC_FILE="$1"
            fi
            shift
            ;;
    esac
done

# Validate required inputs
if [[ "$TEST_LLM" == true ]]; then
    # Test mode - just verify API connectivity
    echo "Testing LLM integration..."
elif [[ "$DIFF_MODE" == true ]]; then
    if [[ -z "$DIFF_FILE" ]]; then
        error "Diff file required when using --diff mode"
    fi
    if [[ -z "$ROOT_SPEC_FILE" ]]; then
        error "Root spec file is REQUIRED when using --diff mode to provide complete validation context"
    fi
    if [[ ! -f "$ROOT_SPEC_FILE" ]]; then
        error "Root spec file not found: $ROOT_SPEC_FILE"
    fi
else
    if [[ -z "$SPEC_FILE" ]]; then
        error "Spec file path is required"
    fi
    if [[ ! -f "$SPEC_FILE" ]]; then
        error "Spec file not found: $SPEC_FILE"
    fi
fi

# Check for API keys
API_TYPE=""
API_KEY=""
if [[ -n "${ANTHROPIC_API_KEY:-}" ]]; then
    API_TYPE="anthropic"
    API_KEY="$ANTHROPIC_API_KEY"
elif [[ -n "${OPENAI_API_KEY:-}" ]]; then
    API_TYPE="openai"
    API_KEY="$OPENAI_API_KEY"
else
    error "Either ANTHROPIC_API_KEY or OPENAI_API_KEY must be set"
fi

debug "API Type: $API_TYPE"

# Create a temporary directory (working directory, not system /tmp)
TMP_DIR="./tmp_spec_validator_$$"
mkdir -p "$TMP_DIR"
trap "rm -rf $TMP_DIR" EXIT

# Read the spec content
SPEC_CONTENT=""
if [[ "$TEST_LLM" == true ]]; then
    # For test mode, we'll use the actual spec content but with a different prompt
    SPEC_CONTENT=$(cat "$SPEC_FILE" 2>/dev/null || echo "Test spec for LLM connectivity")
elif [[ "$DIFF_MODE" == true ]]; then
    if [[ "$DIFF_FILE" == "-" ]]; then
        DIFF_CONTENT=$(cat)
    else
        DIFF_CONTENT=$(cat "$DIFF_FILE")
    fi
    
    # Extract spec file paths from diff and verify they contain spec files
    SPEC_FILES=$(echo "$DIFF_CONTENT" | awk '/^(diff --git|---|\+\+\+)/ && /\.(md|yaml|yml)/ {
        gsub(/^(diff --git a\/|---|\\+\\+\\+\s+[ab]\/)/, "");
        gsub(/\t.*$/, "");
        print
    }' | sort -u)
    
    if [[ -z "$SPEC_FILES" ]]; then
        error "No spec files found in diff"
    fi
    
    debug "Found spec files in diff: $SPEC_FILES"
    
    # Read the root spec file for context
    ROOT_CONTENT=$(cat "$ROOT_SPEC_FILE")
    
    # Combine root file content with diff for complete context
    SPEC_CONTENT="Original spec file content:
$ROOT_CONTENT

Changes being validated (from diff):
$DIFF_CONTENT"
else
    SPEC_CONTENT=$(cat "$SPEC_FILE")
fi

# Read the reference spec validator spec
SPEC_VALIDATOR_SPEC_PATH="$(dirname "$0")/../specs/spec-validator.md"
if [[ ! -f "$SPEC_VALIDATOR_SPEC_PATH" ]]; then
    error "Reference spec validator specification not found at: $SPEC_VALIDATOR_SPEC_PATH"
fi
SPEC_VALIDATOR_SPEC=$(cat "$SPEC_VALIDATOR_SPEC_PATH")

# Read the prompt template
PROMPT_TEMPLATE_PATH="$(dirname "$0")/../scripts/promptTemplate-GPT.sh"
if [[ ! -f "$PROMPT_TEMPLATE_PATH" ]]; then
    error "Prompt template not found at: $PROMPT_TEMPLATE_PATH"
fi
PROMPT_TEMPLATE=$(cat "$PROMPT_TEMPLATE_PATH")

# Prepare the full prompt
if [[ "$TEST_LLM" == true ]]; then
    # Test mode uses a different prompt to verify LLM connectivity
    FULL_PROMPT="Please provide a summary of the content you received in less than 300 words. Your response must include:
1. A quick summary of the files or specs you were given
2. Identification of the type of content (spec file, configuration, etc.)
3. Demonstration of successful parsing and understanding of the input

The input context is from file: ${SPEC_FILE:-"test input"}

Content:
$SPEC_CONTENT"
else
    # Normal validation mode
    FULL_PROMPT="$PROMPT_TEMPLATE

Reference Spec Validator Specification:
$SPEC_VALIDATOR_SPEC

Spec to validate:
$SPEC_CONTENT"
fi

if [[ "$DRY_RUN" == true ]]; then
    echo "=== PROMPT THAT WOULD BE SENT ==="
    echo "$FULL_PROMPT"
    exit 0
fi

debug "Prompt length: $(echo "$FULL_PROMPT" | wc -c) characters"

# Function to call OpenAI API
call_openai() {
    local model="$1"
    debug "Calling OpenAI API with model: $model"
    
    # Escape the prompt content using jq to handle newlines and special characters
    local escaped_prompt
    escaped_prompt=$(echo "$FULL_PROMPT" | jq -Rs .)
    
    # Create the request JSON using heredoc
    local system_message
    if [[ "$TEST_LLM" == true ]]; then
        system_message="You are a helpful assistant. Provide a clear, concise summary as requested."
    else
        system_message="You are a Spec Validator. Always respond with valid JSON only. Do not include any markdown formatting or code blocks in your response."
    fi
    
    cat > "$TMP_DIR/request.json" <<EOF
{
  "model": "$model",
  "messages": [
    {
      "role": "system",
      "content": "$system_message"
    },
    {
      "role": "user",
      "content": $escaped_prompt
    }
  ],
  "temperature": 0.1
}
EOF
    
    local response
    response=$(curl -s -X POST https://api.openai.com/v1/chat/completions \
        -H "Content-Type: application/json" \
        -H "Authorization: Bearer $API_KEY" \
        -d @"$TMP_DIR/request.json")
    
    debug "OpenAI response received"
    
    # Check for errors
    if echo "$response" | jq -e '.error' >/dev/null 2>&1; then
        debug "OpenAI API error: $(echo "$response" | jq -r '.error.message')"
        return 1
    fi
    
    # Extract the content
    local content
    content=$(echo "$response" | jq -r '.choices[0].message.content // empty')
    if [[ -z "$content" ]]; then
        debug "Empty content from OpenAI response"
        return 1
    fi
    echo "$content"
}

# Function to call Anthropic API
call_anthropic() {
    local model="$1"
    debug "Calling Anthropic API with model: $model"
    
    # Escape the prompt content using jq
    local escaped_prompt
    if [[ "$TEST_LLM" == true ]]; then
        escaped_prompt=$(echo "You are a helpful assistant. Provide a clear, concise summary as requested.

$FULL_PROMPT" | jq -Rs .)
    else
        escaped_prompt=$(echo "$FULL_PROMPT" | jq -Rs .)
    fi
    
    # Create the request JSON using heredoc
    cat > "$TMP_DIR/request.json" <<EOF
{
  "model": "$model",
  "max_tokens": 4096,
  "messages": [
    {
      "role": "user",
      "content": $escaped_prompt
    }
  ]
}
EOF
    
    local response
    response=$(curl -s -X POST https://api.anthropic.com/v1/messages \
        -H "Content-Type: application/json" \
        -H "x-api-key: $API_KEY" \
        -H "anthropic-version: 2023-06-01" \
        -d @"$TMP_DIR/request.json")
    
    debug "Anthropic response received"
    
    # Check for errors
    if echo "$response" | jq -e '.error' >/dev/null 2>&1; then
        debug "Anthropic API error: $(echo "$response" | jq -r '.error.message')"
        return 1
    fi
    
    # Extract the content
    echo "$response" | jq -r '.content[0].text // empty'
}

# Try models in preference order with API-model compatibility check
RESULT=""
MODEL_USED=""

for model in "${MODEL_PREFERENCE[@]}"; do
    debug "Trying model: $model"
    
    # Skip models that don't match the API type
    if [[ "$API_TYPE" == "anthropic" ]] && [[ "$model" == claude* ]]; then
        if RESULT=$(call_anthropic "$model" 2>/dev/null) && [[ -n "$RESULT" ]]; then
            MODEL_USED="$model"
            debug "Successfully used model: $model"
            break
        fi
    elif [[ "$API_TYPE" == "openai" ]] && [[ "$model" == gpt* ]]; then
        if RESULT=$(call_openai "$model" 2>/dev/null) && [[ -n "$RESULT" ]]; then
            MODEL_USED="$model"
            debug "Successfully used model: $model"
            break
        fi
    fi
    debug "Model $model failed or incompatible with API type $API_TYPE"
done

if [[ -z "$RESULT" ]]; then
    error "Failed to get response from any compatible model"
fi

if [[ "$DEBUG" == "1" ]]; then
    echo "[DEBUG] Raw LLM response:" >&2
    echo "$RESULT" >&2
    echo "[DEBUG] End raw response" >&2
fi

# Handle test mode
if [[ "$TEST_LLM" == true ]]; then
    echo "=== LLM Integration Test ==="
    echo "API Type: $API_TYPE"
    echo "Available Models: ${MODEL_PREFERENCE[*]}"
    echo "Model Used: $MODEL_USED"
    echo "Response Length: $(echo "$RESULT" | wc -c) characters"
    echo "Status: SUCCESS"
    echo
    echo "Content Summary Response:"
    echo "------------------------"
    echo "$RESULT"
    echo "------------------------"
    exit 0
fi

# Strip markdown code blocks from LLM responses before parsing
CLEAN_RESULT=$(echo "$RESULT" | sed -e 's/^```json//' -e 's/^```//' -e 's/```$//')

# Provide fallback JSON structure for parse failures
PARSED_RESULT=$(echo "$CLEAN_RESULT" | jq -c '.' 2>/dev/null || echo '{"status":"FAIL","model_used":"parse_error","summary":{"pass":0,"warn":0,"fail":1},"failures":[{"line":0,"message":"Failed to parse API response"}],"warnings":[],"suggestions":[],"clarifying_questions":[]}')

# Ensure model_used metadata is correct (overwrite LLM response)
PARSED_RESULT=$(echo "$PARSED_RESULT" | jq --arg model "$MODEL_USED" '.model_used = $model')

# Handle null values in JSON responses - replace with meaningful defaults
PARSED_RESULT=$(echo "$PARSED_RESULT" | jq '
    .failures[] |= (if .message == null then .message = "Details unavailable" else . end) |
    .warnings[] |= (if .message == null then .message = "Warning details unavailable" else . end) |
    .suggestions[] |= (if .text == null then .text = "Suggestion details unavailable" else . end) |
    .clarifying_questions |= map(if . == null then "Question details unavailable" else . end)
')

# Output results
if [[ "$JSON_OUTPUT" == true ]]; then
    echo "$PARSED_RESULT" | jq '.'
else
    # Human-readable output
    STATUS=$(echo "$PARSED_RESULT" | jq -r '.status // "UNKNOWN"')
    MODEL=$(echo "$PARSED_RESULT" | jq -r '.model_used // "unknown"')
    PASS_COUNT=$(echo "$PARSED_RESULT" | jq -r '.summary.pass // 0')
    WARN_COUNT=$(echo "$PARSED_RESULT" | jq -r '.summary.warn // 0')
    FAIL_COUNT=$(echo "$PARSED_RESULT" | jq -r '.summary.fail // 0')
    
    if [[ "$DIFF_MODE" == true ]]; then
        echo "[VALIDATION] $ROOT_SPEC_FILE (diff mode)"
    else
        echo "[VALIDATION] $SPEC_FILE"
    fi
    echo "Status: $STATUS"
    echo "Model Used: $MODEL"
    echo
    
    # Failures
    if [[ $(echo "$PARSED_RESULT" | jq -r '.failures | length') -gt 0 ]]; then
        echo "Failures (requires human review):"
        echo "$PARSED_RESULT" | jq -r '.failures[] | "- Line \(.line // 0): \(.message // "Details unavailable")"'
        echo
    fi
    
    # Warnings
    if [[ $(echo "$PARSED_RESULT" | jq -r '.warnings | length') -gt 0 ]]; then
        echo "Warnings (agent-fixable):"
        echo "$PARSED_RESULT" | jq -r '.warnings[] | "- Line \(.line // 0): \(.message // "Warning details unavailable")"'
        echo
    fi
    
    # Suggestions
    if [[ $(echo "$PARSED_RESULT" | jq -r '.suggestions | length') -gt 0 ]]; then
        echo "Suggestions:"
        echo "$PARSED_RESULT" | jq -r '.suggestions[] | "- [\(.level // "INFO")] \(.text // "Suggestion details unavailable")"'
        echo
    fi
    
    # Clarifying questions
    if [[ $(echo "$PARSED_RESULT" | jq -r '.clarifying_questions | length') -gt 0 ]]; then
        echo "Clarifying Questions:"
        echo "$PARSED_RESULT" | jq -r '.clarifying_questions[] | "- \(. // "Question details unavailable")"'
        echo
    fi
    
    echo "Summary:"
    echo "PASS: $PASS_COUNT | WARN: $WARN_COUNT | FAIL: $FAIL_COUNT"
fi

# Exit with appropriate code
STATUS=$(echo "$PARSED_RESULT" | jq -r '.status // "FAIL"')
case "$STATUS" in
    PASS|WARN)
        exit 0
        ;;
    FAIL)
        exit 1
        ;;
    *)
        exit 2
        ;;
esac